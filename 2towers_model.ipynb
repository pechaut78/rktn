{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ancien model : Tentative d'exexcution d'un model VGG16 et Embeddings NLP en simultané\n",
    "\n",
    "Code à finaliser, ne fonctionne plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam,Adagrad\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import VGG19\n",
    "from keras.applications import EfficientNetB0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "from RktnChallenge.RktnModel import ModelTrainer\n",
    "\n",
    "\n",
    "# PARAMS  de base\n",
    "PATH = \"images/crop224/\"\n",
    "img_size = 224\n",
    "depth = 3\n",
    "\n",
    "from RktnChallenge.RktnModel import ModelTrainer\n",
    "\n",
    "trainer = ModelTrainer(\"data.csv\",PATH)\n",
    "\n",
    "list_tags = trainer.data.prdtypecode.unique().tolist()\n",
    "num_categories = len(list_tags)\n",
    "nb_Sample = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from RktnChallenge.RktnModel import ModelTrainer\n",
    "\n",
    "trainer = ModelTrainer(\"data_tr_lemm.csv\",PATH)\n",
    "\n",
    "\n",
    "list_tags = trainer.data.prdtypecode.unique().tolist()\n",
    "num_categories = len(list_tags)\n",
    "\n",
    "\n",
    "\n",
    "y = trainer.encoder.fit_transform(trainer.data[\"prdtypecode\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class MultiInputDataGenerator:\n",
    "    def __init__(self, image_data_gen: ImageDataGenerator):\n",
    "        self.image_data_gen = image_data_gen\n",
    "\n",
    "    def flow_from_dataframe(self, dataframe, x_col_img, x_col_emb, y_col, target_size, batch_size,classes):\n",
    "        # Image generator\n",
    "        img_gen = self.image_data_gen.flow_from_dataframe(\n",
    "            dataframe,\n",
    "            x_col=x_col_img,\n",
    "            y_col=y_col,\n",
    "            target_size=target_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode=\"categorical\",\n",
    "            seed=42,\n",
    "            classes = classes,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        while True:\n",
    "            img_batch, label_batch = next(img_gen)\n",
    "            idx = (img_gen.batch_index - 1) * img_gen.batch_size\n",
    "            emb_batch = dataframe[x_col_emb].iloc[idx: idx + batch_size].to_numpy()\n",
    "            emb_batch = np.array(emb_batch.tolist())\n",
    "            yield [img_batch, emb_batch], label_batch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n",
    "image_data_gen = ImageDataGenerator(preprocessing_function = preprocessing_function)\n",
    "multi_gen = MultiInputDataGenerator(image_data_gen)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supposons que df est votre dataframe\n",
    "train_df, temp_df = train_test_split(df_copy, test_size=0.3, random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "\n",
    "train_generator = multi_gen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col_img=\"imgname\",\n",
    "    x_col_emb=\"tokens\",\n",
    "    y_col=\"prdtypecode\",\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    classes=classes\n",
    ")\n",
    "valid_generator = multi_gen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    x_col_img=\"imgname\",\n",
    "    x_col_emb=\"tokens\",\n",
    "    y_col=\"prdtypecode\",\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    classes=classes\n",
    ")\n",
    "test_generator = multi_gen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    x_col_img=\"imgname\",\n",
    "    x_col_emb=\"tokens\",\n",
    "    y_col=\"prdtypecode\",\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    classes=classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_input (InputLayer)    [(None, 100, 100, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " vgg16 (Functional)          (None, None, None, 512)      1471468   ['image_input[0][0]']         \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 512)                  0         ['vgg16[0][0]']               \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 512)                  2048      ['global_average_pooling2d_2[0\n",
      " chNormalization)                                                   ][0]']                        \n",
      "                                                                                                  \n",
      " text_input (InputLayer)     [(None, 922)]                0         []                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 512)                  262656    ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 922, 600)             8530020   ['text_input[0][0]']          \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 512)                  0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 553200)               0         ['embedding_2[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 553712)               0         ['dropout_3[0][0]',           \n",
      " )                                                                   'flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 27)                   1495025   ['concatenate_1[0][0]']       \n",
      "                                                          1                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 115229843 (439.57 MB)\n",
      "Trainable params: 102873939 (392.43 MB)\n",
      "Non-trainable params: 12355904 (47.13 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Embedding, LSTM, GlobalAveragePooling2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import VGG19\n",
    "from keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# La partie Image\n",
    "input_image = Input(shape=(img_size, img_size, depth), name=\"image_input\")\n",
    "net = VGG16(weights='imagenet', include_top=False) \n",
    "x_image = net(input_image)\n",
    "\n",
    "for layer in net.layers[:-2]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "x_image = tf.keras.layers.GlobalAveragePooling2D()(x_image)\n",
    "x_image = tf.keras.layers.BatchNormalization()(x_image)\n",
    "x_image = Dense(512, activation='relu')(x_image)\n",
    "x_image = Dropout(0.3)(x_image)\n",
    "\n",
    "\n",
    "# La partie Texte\n",
    "max_words = trainer.max_seq_length\n",
    "vocab_size = trainer.vocab_size  # Total vocabulary size\n",
    "embedding_dim = 600  # Embedding dimensions\n",
    "\n",
    "input_text = Input(shape=(max_words,), name=\"text_input\")\n",
    "x_text = Embedding(vocab_size, embedding_dim)(input_text)\n",
    "x_text = Flatten()(x_text)\n",
    "\n",
    "# Le merge des deux towers\n",
    "merged = tf.keras.layers.concatenate([x_image, x_text])\n",
    "\n",
    "output = Dense(27, activation='softmax')(merged)\n",
    "\n",
    "\n",
    "model = Model(inputs=[input_image, input_text], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec pondération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(512,) dtype=float32>\n",
      "  <tf.Variable 'Variable:0' shape=(512,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_input (InputLayer)    [(None, 100, 100, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " vgg16 (Functional)          (None, None, None, 512)      1471468   ['image_input[0][0]']         \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " text_input (InputLayer)     [(None, 922)]                0         []                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 512)                  0         ['vgg16[0][0]']               \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 922, 150)             2132505   ['text_input[0][0]']          \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 512)                  2048      ['global_average_pooling2d_1[0\n",
      " chNormalization)                                                   ][0]']                        \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 138300)               0         ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 512)                  262656    ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 512)                  7081011   ['flatten_1[0][0]']           \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 512)                  0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 512)                  0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 512)                  0         ['dropout_1[0][0]',           \n",
      "                                                                     'dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 128)                  65664     ['lambda[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 27)                   3483      ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 107183701 (408.87 MB)\n",
      "Trainable params: 92467989 (352.74 MB)\n",
      "Non-trainable params: 14715712 (56.14 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Embedding, LSTM, GlobalAveragePooling2D, Lambda\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import VGG19\n",
    "from keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# La partie Image\n",
    "input_image = Input(shape=(img_size, img_size, depth), name=\"image_input\")\n",
    "net = VGG16(weights='imagenet', include_top=False) \n",
    "x_image = net(input_image)\n",
    "\n",
    "for layer in net.layers[:]:\n",
    "        layer.trainable = False\n",
    "         \n",
    "x_image = tf.keras.layers.GlobalAveragePooling2D()(x_image)\n",
    "x_image = tf.keras.layers.BatchNormalization()(x_image)\n",
    "x_image = Dense(512, activation='relu')(x_image)\n",
    "x_image = Dropout(0.3)(x_image)\n",
    "\n",
    "\n",
    "# La partie Texte\n",
    "max_words = trainer.max_seq_length\n",
    "vocab_size = trainer.vocab_size  # Total vocabulary size\n",
    "embedding_dim = 150  # Embedding dimensions\n",
    "\n",
    "input_text = Input(shape=(max_words,), name=\"text_input\")\n",
    "x_text = Embedding(vocab_size, embedding_dim)(input_text)\n",
    "x_text = Flatten()(x_text)\n",
    "#x_text = LSTM(128)(x_text)\n",
    "x_text = Dense(512, activation='relu')(x_text)\n",
    "x_text = Dropout(0.3)(x_text)\n",
    "\n",
    "# Le merge des deux towers\n",
    "# Poids pour la moyenne pondérée\n",
    "w_img = tf.Variable(initial_value=tf.ones([512])*0.5, trainable=True, dtype=tf.float32) # initialisé à 0.5, mais entraînable\n",
    "w_emb = tf.Variable(initial_value=tf.ones([512])*0.5, trainable=True, dtype=tf.float32) # initialisé à 0.5, mais entraînable\n",
    "\n",
    "# Fusion moyenne pondérée\n",
    "moyenne_features = Lambda(lambda features: w_img * features[0] + w_emb * features[1])([x_image, x_text])\n",
    "x_merge = Dense(128, activation='relu')(moyenne_features)\n",
    "output = Dense(27, activation='softmax')(x_merge)\n",
    "\n",
    "\n",
    "model = Model(inputs=[input_image, input_text], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_2\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 922) dtype=int32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/pec/Rktn/2towers_model.ipynb Cellule 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pec/Rktn/2towers_model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pec/Rktn/2towers_model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     X_train,y_train,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pec/Rktn/2towers_model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pec/Rktn/2towers_model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pec/Rktn/2towers_model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file37ugvyxb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_2\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 922) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2961/Unknown - 77s 26ms/step - loss: 0.8589 - accuracy: 0.7255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 23:30:26.001819: W tensorflow/core/framework/op_kernel.cc:1816] INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (0,) where an element of shape (None, None) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (0,) where an element of shape (None, None) was expected.\n",
      "\n",
      "\n",
      "2023-08-30 23:30:26.048887: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 13532273789714353523\n",
      "2023-08-30 23:30:26.048930: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 8503134319588348884\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (0,) where an element of shape (None, None) was expected.\nTraceback (most recent call last):\n\n  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (0,) where an element of shape (None, None) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (0,) where an element of shape (None, None) was expected.\nTraceback (most recent call last):\n\n  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (0,) where an element of shape (None, None) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_84359]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      2\u001b[0m     train_generator,\n\u001b[1;32m      3\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalid_generator,\n\u001b[1;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (0,) where an element of shape (None, None) was expected.\nTraceback (most recent call last):\n\n  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (0,) where an element of shape (None, None) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (0,) where an element of shape (None, None) was expected.\nTraceback (most recent call last):\n\n  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (0,) where an element of shape (None, None) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_84359]"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=1\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

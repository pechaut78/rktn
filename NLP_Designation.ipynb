{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele Simple: Génération des embeddings pour Designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "\n",
    "from RktnChallenge.RktnModel import ModelTrainer\n",
    "from RktnChallenge.preprocessing.tokenizeString import tokenizeString\n",
    "from RktnChallenge.preprocessing.filterStopWords import filterStopWords\n",
    "from RktnChallenge.preprocessing.mergeFeatures import mergeFeatures\n",
    "from RktnChallenge.preprocessing.mostOccur import mostOccur\n",
    "from RktnChallenge.preprocessing.Dropper import Dropper\n",
    "from RktnChallenge.preprocessing.TokenListToString import TokenListToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RktnModel = ModelTrainer(\"data_tr_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['desi_encoder.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X = RktnModel.data[\"merged_desi_desc\"]\n",
    "\n",
    "RktnModel.create_vectorizer(name=\"tokenizer\", X = _X, ngram_range=(1,3))\n",
    "\n",
    "X_data = RktnModel.vectorizer_transform(_X)     \n",
    "\n",
    "\n",
    "y = RktnModel.encodeLabel(\"prdtypecode\")\n",
    "label_size = RktnModel.getLabelSize()\n",
    "\n",
    "import json\n",
    "#on sauve le vectorizer\n",
    "tokenizer_json = RktnModel.tokenizer.to_json()\n",
    "with open('desi_tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
    "\n",
    "import joblib\n",
    "joblib.dump(RktnModel.encoder, 'desi_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = X_data\n",
    "y_train = y\n",
    "print(RktnModel.max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition d'un modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 47, 150)           10582650  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 7050)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                190377    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10773027 (41.10 MB)\n",
      "Trainable params: 10773027 (41.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, GRUCell,RNN,GRU, Dense,Dropout,GlobalAveragePooling2D, LSTM, Flatten, Input\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "_latent_dim = 150\n",
    "\n",
    "vocab_size = RktnModel.vocab_size\n",
    "max_seq_length = RktnModel.max_seq_length\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=_latent_dim, input_length=max_seq_length, mask_zero=True),     \n",
    "    Flatten(),   \n",
    "    #Dense(units=nb_units, activation=\"relu\"),\n",
    "    Dense(units=label_size, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    " \n",
    "optimizer = AdamW(weight_decay=0.01, learning_rate=0.001) \n",
    "model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "544/544 [==============================] - 22s 40ms/step - loss: 1.5857 - accuracy: 0.5803 - val_loss: 0.8273 - val_accuracy: 0.7713\n",
      "Epoch 2/4\n",
      "544/544 [==============================] - 7s 13ms/step - loss: 0.5084 - accuracy: 0.8656 - val_loss: 0.6360 - val_accuracy: 0.8103\n",
      "Epoch 3/4\n",
      "544/544 [==============================] - 6s 10ms/step - loss: 0.2180 - accuracy: 0.9494 - val_loss: 0.6139 - val_accuracy: 0.8139\n",
      "Epoch 4/4\n",
      "544/544 [==============================] - 4s 8ms/step - loss: 0.1005 - accuracy: 0.9788 - val_loss: 0.6253 - val_accuracy: 0.8112\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=4, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model.save(\"model_designation.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

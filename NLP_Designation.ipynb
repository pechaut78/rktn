{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Désactiver le GPU en définissant CUDA_VISIBLE_DEVICES à un vide#\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import RktnChallenge.RktnModel\n",
    "importlib.reload(RktnChallenge.RktnModel)\n",
    "from RktnChallenge.RktnModel import ModelTrainer\n",
    "\n",
    "import RktnChallenge.preprocessing.tokenizeString\n",
    "importlib.reload(RktnChallenge.preprocessing.tokenizeString)\n",
    "from RktnChallenge.preprocessing.tokenizeString import tokenizeString\n",
    "\n",
    "import RktnChallenge.preprocessing.filterStopWords\n",
    "importlib.reload(RktnChallenge.preprocessing.filterStopWords)\n",
    "from RktnChallenge.preprocessing.filterStopWords import filterStopWords\n",
    "\n",
    "\n",
    "import RktnChallenge.preprocessing.mergeFeatures\n",
    "importlib.reload(RktnChallenge.preprocessing.mergeFeatures)\n",
    "from RktnChallenge.preprocessing.mergeFeatures import mergeFeatures\n",
    "\n",
    "import RktnChallenge.preprocessing.mostOccur\n",
    "importlib.reload(RktnChallenge.preprocessing.mostOccur)\n",
    "from RktnChallenge.preprocessing.mostOccur import mostOccur\n",
    "\n",
    "import RktnChallenge.preprocessing.Dropper\n",
    "importlib.reload(RktnChallenge.preprocessing.Dropper)\n",
    "from RktnChallenge.preprocessing.Dropper import Dropper\n",
    "\n",
    "import RktnChallenge.preprocessing.TokenListToString\n",
    "importlib.reload(RktnChallenge.preprocessing.TokenListToString)\n",
    "from RktnChallenge.preprocessing.TokenListToString import TokenListToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RktnModel = ModelTrainer(\"data_tr_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "On crop puis on merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pec/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "addendum = ['a','à','<p>','<b>','<div>','<em>','<br>']\n",
    "\n",
    "#on tokenise et retire les stopwords designation\n",
    "\n",
    "desi_tokenize= tokenizeString(\"designation_tkn\",\"designation\")\n",
    "desi_stopwords = filterStopWords(\"merged_desi_desc\", \"designation_tkn\"\n",
    "                                 ,lang=[\"english\",\"french\"],addendum=addendum)\n",
    "\n",
    "\n",
    "\n",
    "RktnModel.initPreprocess()\n",
    "RktnModel.addPreprocessStep(\"tokenize designation\",desi_tokenize) # transformation en token\n",
    "RktnModel.addPreprocessStep(\"filter designation\",desi_stopwords)  # filtrage des stopwords\n",
    "\n",
    "\n",
    "\n",
    "#RktnModel.addPreprocessStep(\"cleaning\",cleanDropper) # on clean les colonnes crées\n",
    "RktnModel.data = RktnModel.preprocess()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "81.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['desi_encoder.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X = RktnModel.data[\"merged_desi_desc\"]\n",
    "\n",
    "RktnModel.create_vectorizer(name=\"tokenizer\", X = _X, ngram_range=(1,3))\n",
    "\n",
    "X_data = RktnModel.vectorizer_transform(_X)     \n",
    "\n",
    "\n",
    "y = RktnModel.encodeLabel(\"prdtypecode\")\n",
    "label_size = RktnModel.getLabelSize()\n",
    "\n",
    "import json\n",
    "#on sauve le vectorizer\n",
    "tokenizer_json = RktnModel.tokenizer.to_json()\n",
    "with open('desi_tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
    "\n",
    "import joblib\n",
    "joblib.dump(RktnModel.encoder, 'desi_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = X_data\n",
    "y_train = y\n",
    "print(RktnModel.max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition d'un modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 47, 150)           10582650  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 7050)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                190377    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10773027 (41.10 MB)\n",
      "Trainable params: 10773027 (41.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, GRUCell,RNN,GRU, Dense,Dropout,GlobalAveragePooling2D, LSTM, Flatten, Input\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "_latent_dim = 150\n",
    "\n",
    "vocab_size = RktnModel.vocab_size\n",
    "max_seq_length = RktnModel.max_seq_length\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=_latent_dim, input_length=max_seq_length, mask_zero=True),     \n",
    "    Flatten(),   \n",
    "    #Dense(units=nb_units, activation=\"relu\"),\n",
    "    Dense(units=label_size, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    " \n",
    "optimizer = AdamW(weight_decay=0.01, learning_rate=0.001) \n",
    "model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "544/544 [==============================] - 22s 40ms/step - loss: 1.5857 - accuracy: 0.5803 - val_loss: 0.8273 - val_accuracy: 0.7713\n",
      "Epoch 2/4\n",
      "544/544 [==============================] - 7s 13ms/step - loss: 0.5084 - accuracy: 0.8656 - val_loss: 0.6360 - val_accuracy: 0.8103\n",
      "Epoch 3/4\n",
      "544/544 [==============================] - 6s 10ms/step - loss: 0.2180 - accuracy: 0.9494 - val_loss: 0.6139 - val_accuracy: 0.8139\n",
      "Epoch 4/4\n",
      "544/544 [==============================] - 4s 8ms/step - loss: 0.1005 - accuracy: 0.9788 - val_loss: 0.6253 - val_accuracy: 0.8112\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=4, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pec/miniconda3/envs/tfGPU/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#y_pred_test = model.predict(X_test)\n",
    "#y_pred_id = y_pred_test.argmax(axis=-1)\n",
    "\n",
    "#RktnModel.evaluateTestResults(y_test,y_pred_id)\n",
    "\n",
    "\n",
    "model.save(\"model_designation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Désactiver le GPU en définissant CUDA_VISIBLE_DEVICES à un vide#\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 00:00:41.419306: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-06 00:00:41.798533: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 00:00:43.174387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import RktnChallenge.RktnModel\n",
    "importlib.reload(RktnChallenge.RktnModel)\n",
    "from RktnChallenge.RktnModel import ModelTrainer\n",
    "\n",
    "import RktnChallenge.preprocessing.tokenizeString\n",
    "importlib.reload(RktnChallenge.preprocessing.tokenizeString)\n",
    "from RktnChallenge.preprocessing.tokenizeString import tokenizeString\n",
    "\n",
    "import RktnChallenge.preprocessing.filterStopWords\n",
    "importlib.reload(RktnChallenge.preprocessing.filterStopWords)\n",
    "from RktnChallenge.preprocessing.filterStopWords import filterStopWords\n",
    "\n",
    "\n",
    "import RktnChallenge.preprocessing.mergeFeatures\n",
    "importlib.reload(RktnChallenge.preprocessing.mergeFeatures)\n",
    "from RktnChallenge.preprocessing.mergeFeatures import mergeFeatures\n",
    "\n",
    "import RktnChallenge.preprocessing.mostOccur\n",
    "importlib.reload(RktnChallenge.preprocessing.mostOccur)\n",
    "from RktnChallenge.preprocessing.mostOccur import mostOccur\n",
    "\n",
    "import RktnChallenge.preprocessing.Dropper\n",
    "importlib.reload(RktnChallenge.preprocessing.Dropper)\n",
    "from RktnChallenge.preprocessing.Dropper import Dropper\n",
    "\n",
    "import RktnChallenge.preprocessing.TokenListToString\n",
    "importlib.reload(RktnChallenge.preprocessing.TokenListToString)\n",
    "from RktnChallenge.preprocessing.TokenListToString import TokenListToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RktnModel = ModelTrainer(\"data_tr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "On crop puis on merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On merge et on crop ensuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pec/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/pec/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "addendum = ['a','à','<p>','<b>','<div>','<em>','<br>']\n",
    "\n",
    "#on tokenise et retire les stopwords designation\n",
    "\n",
    "desi_tokenize= tokenizeString(\"designation_tkn\",\"designation\")\n",
    "desi_stopwords = filterStopWords(\"designation_tkn\", \"designation_tkn\"\n",
    "                                 ,lang=[\"english\",\"french\"],addendum=addendum)\n",
    "\n",
    "\n",
    "#on tokenise et retire les stopwords description\n",
    "desc_tokenize= tokenizeString(\"description_tkn\",\"description\")\n",
    "desc_stopwords = filterStopWords(\"description_tkn\", \"description_tkn\"\n",
    "                                 ,lang=[\"english\",\"french\"],addendum=addendum)\n",
    "\n",
    "\n",
    "merge_desi_desc = mergeFeatures(\"merged\",\"designation_tkn\",\"description_tkn\")\n",
    "desc_mostOccur= mostOccur(\"merged_desi_desc\",\"merged\",100,100)\n",
    "\n",
    "\n",
    "toDrop = [\"designation_tkn\",\"description_tkn\",\"merged\"]\n",
    "cleanDropper = Dropper(column_to_drop = toDrop)\n",
    "toString = TokenListToString(\"merged_desi_desc\",\"merged_desi_desc\")\n",
    "\n",
    "RktnModel.initPreprocess()\n",
    "RktnModel.addPreprocessStep(\"tokenize designation\",desi_tokenize) # transformation en token\n",
    "RktnModel.addPreprocessStep(\"filter designation\",desi_stopwords)  # filtrage des stopwords\n",
    "RktnModel.addPreprocessStep(\"tokenize description\",desc_tokenize) # transformation en token\n",
    "RktnModel.addPreprocessStep(\"filter description\",desc_stopwords)  # filtrage des stopwords\n",
    "RktnModel.addPreprocessStep(\"merge designation and desc\",merge_desi_desc) # merge desi&desc\n",
    "RktnModel.addPreprocessStep(\"desc reduce\",desc_mostOccur)         # Limite en taille\n",
    "RktnModel.addPreprocessStep(\"tostring\",toString) # merge desi&desc\n",
    "\n",
    "#RktnModel.addPreprocessStep(\"cleaning\",cleanDropper) # on clean les colonnes crées\n",
    "RktnModel.preprocess()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = RktnModel.data[\"merged_desi_desc\"]\n",
    "\n",
    "max_features = 13000\n",
    "\n",
    "RktnModel.create_vectorizer(name=\"tfidf\", X = _X, ngram_range=(1,3),max_features=max_features)\n",
    "X_data = RktnModel.vectorizer_transform(_X)     \n",
    "\n",
    "\n",
    "y = RktnModel.encodeLabel(\"prdtypecode\")\n",
    "label_size = RktnModel.getLabelSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y, test_size = 0.20, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del RktnModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition d'un modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 13000)             169013000 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13000)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6000)              78006000  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6000)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              6145024   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 27)                6939      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 253827091 (968.27 MB)\n",
      "Trainable params: 253827091 (968.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 00:07:25.344672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-06 00:07:25.636586: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-06 00:07:25.637052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-06 00:07:25.639694: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-06 00:07:25.639997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-06 00:07:25.640315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-06 00:07:27.077694: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-06 00:07:27.078074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-06 00:07:27.078086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-09-06 00:07:27.078360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-06 00:07:27.078412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10600 MB memory:  -> device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, GRUCell,RNN,GRU, Dense,Dropout,GlobalAveragePooling2D, LSTM, Flatten, Input\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=max_features, activation=\"relu\", input_shape=(max_features,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=6000, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=1024, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=512, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=256, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=label_size, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    " \n",
    "optimizer = AdamW(weight_decay=0.01, learning_rate=0.001) \n",
    "model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 00:07:39.915842: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f502cb7b450 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-06 00:07:39.915901: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2023-09-06 00:07:39.981044: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-06 00:07:40.321404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-09-06 00:07:40.538750: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544/544 [==============================] - 44s 75ms/step - loss: 1.2352 - accuracy: 0.6515 - val_loss: 0.8338 - val_accuracy: 0.7713\n",
      "Epoch 2/10\n",
      "544/544 [==============================] - 39s 72ms/step - loss: 0.6059 - accuracy: 0.8323 - val_loss: 0.7657 - val_accuracy: 0.7914\n",
      "Epoch 3/10\n",
      "544/544 [==============================] - 40s 73ms/step - loss: 0.3884 - accuracy: 0.8891 - val_loss: 0.8081 - val_accuracy: 0.7951\n",
      "Epoch 4/10\n",
      "544/544 [==============================] - 40s 73ms/step - loss: 0.2759 - accuracy: 0.9233 - val_loss: 0.9476 - val_accuracy: 0.7952\n",
      "Epoch 5/10\n",
      "544/544 [==============================] - 39s 72ms/step - loss: 0.2082 - accuracy: 0.9414 - val_loss: 1.0776 - val_accuracy: 0.7912\n",
      "Epoch 6/10\n",
      "544/544 [==============================] - 40s 74ms/step - loss: 0.1735 - accuracy: 0.9518 - val_loss: 1.1961 - val_accuracy: 0.7877\n",
      "Epoch 7/10\n",
      "544/544 [==============================] - 40s 74ms/step - loss: 0.1489 - accuracy: 0.9585 - val_loss: 1.3679 - val_accuracy: 0.7902\n",
      "Epoch 8/10\n",
      "544/544 [==============================] - 40s 74ms/step - loss: 0.1405 - accuracy: 0.9612 - val_loss: 1.2669 - val_accuracy: 0.7908\n",
      "Epoch 9/10\n",
      "544/544 [==============================] - 41s 76ms/step - loss: 0.1324 - accuracy: 0.9640 - val_loss: 1.5673 - val_accuracy: 0.7902\n",
      "Epoch 10/10\n",
      "544/544 [==============================] - 41s 75ms/step - loss: 0.1266 - accuracy: 0.9662 - val_loss: 1.5014 - val_accuracy: 0.7907\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_feature à 1000\n",
    "si taille = 1 52%\n",
    "si taille = 2 64%\n",
    "si taille = 400 76%\n",
    "si taille = 1000 76%\n",
    "\n",
    "je fais varier max_feature à 13 000\n",
    "si taille = 100 79.52\n",
    "si taille = 1000 78%\n",
    "\n",
    "Max BoW = 76%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
